{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzrAHaqbeE-Q"
      },
      "source": [
        "CSE4022 Natural Language Processing\n",
        "Digital Assignment -1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deepavarshini T\n",
        "20BCE1661"
      ],
      "metadata": {
        "id": "y3Tnkx_DeWxZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4SNkUYoeE-S"
      },
      "source": [
        "1) Utilize Python NLTK (Natural Language Tool Kit) Platform and do the following. \n",
        "Install relevant Packages and Libraries \n",
        "\n",
        "• Explore Brown Corpus and find the size, tokens, categories,  \n",
        "• Find the size of word tokens?  \n",
        "• Find the size of word types?  \n",
        "• Find the size of the category “government”  \n",
        "• List the most frequent tokens  \n",
        "• Count the number of sentences  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SP1qUZsheE-b",
        "outputId": "505894e2-8a6c-423f-e26b-5bfe61033fd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Brown Corpus:  1161192\n",
            "Size of word tokens:  1161192\n",
            "Size of word types:  56057\n",
            "Size of the category 'government':  70117\n",
            "Most frequent tokens:  [('the', 62713), (',', 58334), ('.', 49346), ('of', 36080), ('and', 27915), ('to', 25732), ('a', 21881), ('in', 19536), ('that', 10237), ('is', 10011)]\n",
            "Number of sentences:  57340\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download the Brown Corpus\n",
        "nltk.download('brown')\n",
        "\n",
        "# Import the Brown Corpus\n",
        "from nltk.corpus import brown\n",
        "\n",
        "# Find the size of the Brown Corpus\n",
        "size = len(brown.words())\n",
        "print(\"Size of Brown Corpus: \", size)\n",
        "\n",
        "# Find the size of word tokens\n",
        "tokens = len(brown.words())\n",
        "print(\"Size of word tokens: \", tokens)\n",
        "\n",
        "# Find the size of word types\n",
        "types = len(set(brown.words()))\n",
        "print(\"Size of word types: \", types)\n",
        "\n",
        "# Find the size of the category \"government\"\n",
        "category_size = len(brown.words(categories=['government']))\n",
        "print(\"Size of the category 'government': \", category_size)\n",
        "\n",
        "# List the most frequent tokens\n",
        "fd = nltk.FreqDist(brown.words())\n",
        "print(\"Most frequent tokens: \", fd.most_common(10))\n",
        "\n",
        "# Count the number of sentences\n",
        "sentences = len(brown.sents())\n",
        "print(\"Number of sentences: \", sentences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRdNwOtbeE-d"
      },
      "source": [
        "2) Explore the corpora available in NLTK (any two) \n",
        "• Raw corpus  \n",
        "• POS tagged   \n",
        "• Parsed   \n",
        "• Multilingual aligned  \n",
        "• Spoken language  \n",
        "• Semantic tagged  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag0JTauIeE-e"
      },
      "source": [
        "Answer:  \n",
        "Raw corpus:  \n",
        "The NLTK library includes a variety of raw text corpora, such as the Gutenberg Corpus, which contains a collection of texts from the Gutenberg project. Here is an example of how to access and print the first 100 words from the \"Emma\" novel in the Gutenberg Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QtGndg8zeE-e",
        "outputId": "7d80602f-050d-41ed-d48f-bad029d5a617",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'\", 's', 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'Her']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "emma = gutenberg.words('austen-emma.txt')\n",
        "print(emma[:100])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR3m81hIeE-h"
      },
      "source": [
        "d) Spoken Language Corpus:  \n",
        "The NLTK library includes a variety of spoken language corpora, such as the Switchboard Corpus, which contains a collection of telephone conversations that have been transcribed and POS-tagged. Here is an example of how to access and print the first 10 POS-tagged words from the \"Switchboard\" section of the Switchboard Corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieHWsDDQeE-h"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('switchboard')\n",
        "from nltk.corpus import switchboard\n",
        "\n",
        "switchboard_words = switchboard.tagged_words(categories=['Switchboard'])\n",
        "print(switchboard_words[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNI0iEX_eE-h"
      },
      "source": [
        "e) Semantic Tagged Corpus:  \n",
        "The NLTK library includes a variety of semantic-tagged text corpora, such as the FrameNet Corpus, which contains a collection of texts that have been manually annotated with frame semantic information. Here is an example of how to access and print the first 10 semantic-tagged sentences from the \"FrameNet\" section of the FrameNet Corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEwu44YXeE-h"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('framenet_v15')\n",
        "from nltk.corpus import framenet as fn\n",
        "\n",
        "framenet_sentences = fn.tagged_sents(categories=['FrameNet'])\n",
        "print(framenet_sentences[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek6P3BFCeE-i"
      },
      "source": [
        "3) Create a text corpus with a minimum of 200 words (unique content). Implement the \n",
        "following text processing   \n",
        "• Word segmentation  \n",
        "• Sentence segmentation  \n",
        "• Convert to Lowercase  \n",
        "• Stop words removal  \n",
        "• Stemming  \n",
        "• Lemmatization  \n",
        "• Part of speech tagger  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZWWM3ijfWTe",
        "outputId": "2b04e5d8-5306-41d2-c032-ef442fa040a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4YVExCVUeE-i",
        "outputId": "1ef79a70-fea4-40fc-8ff9-08811462fc39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word segmentation:  ['One', 'day', ',', 'a', 'fox', 'became', 'very', 'hungry', 'as', 'he', 'went', 'to', 'search', 'for', 'some', 'food', '.', 'He', 'searched', 'high', 'and', 'low', ',', 'but', 'couldn', '’', 't', 'find', 'something', 'that', 'he', 'could', 'eat', '.', 'Finally', ',', 'as', 'his', 'stomach', 'rumbled', ',', 'he', 'stumbled', 'upon', 'a', 'farmer', '’', 's', 'wall', '.', 'At', 'the', 'top', 'of', 'the', 'wall', ',', 'he', 'saw', 'the', 'biggest', ',', 'juiciest', 'grapes', 'he', '’', 'd', 'ever', 'seen', '.', 'They', 'had', 'a', 'rich', ',', 'purple', 'color', ',', 'telling', 'the', 'fox', 'they', 'were', 'ready', 'to', 'be', 'eaten', '.', 'To', 'reach', 'the', 'grapes', ',', 'the', 'fox', 'had', 'to', 'jump', 'high', 'in', 'the', 'air', '.', 'As', 'he', 'jumped', ',', 'he', 'opened', 'his', 'mouth', 'to', 'catch', 'the', 'grapes', ',', 'but', 'he', 'missed', '.', 'The', 'fox', 'tried', 'again', 'but', 'missed', 'yet', 'again', '.', 'He', 'tried', 'a', 'few', 'more', 'times', 'but', 'kept', 'failing', '.', 'Finally', ',', 'the', 'fox', 'decided', 'it', 'was', 'time', 'to', 'give', 'up', 'and', 'go', 'home', '.', 'While', 'he', 'walked', 'away', ',', 'he', 'muttered', ',', '“', 'I', '’', 'm', 'sure', 'the', 'grapes', 'were', 'sour', 'anyway', '.', 'The', 'end', '.']\n",
            "Sentence segmentation:  ['One day, a fox became very hungry as he went to search for some food.', 'He searched high and low, but couldn’t find something that he could eat.', 'Finally, as his stomach rumbled, he stumbled upon a farmer’s wall.', 'At the top of the wall, he saw the biggest, juiciest grapes he’d ever seen.', 'They had a rich, purple color, telling the fox they were ready to be eaten.', 'To reach the grapes, the fox had to jump high in the air.', 'As he jumped, he opened his mouth to catch the grapes, but he missed.', 'The fox tried again but missed yet again.', 'He tried a few more times but kept failing.', 'Finally, the fox decided it was time to give up and go home.', 'While he walked away, he muttered, “I’m sure the grapes were sour anyway.', 'The end.']\n",
            "Lowercase:  one day, a fox became very hungry as he went to search for some food. he searched high and low, but couldn’t find something that he could eat.\n",
            "finally, as his stomach rumbled, he stumbled upon a farmer’s wall. at the top of the wall, he saw the biggest, juiciest grapes he’d ever seen.\n",
            "they had a rich, purple color, telling the fox they were ready to be eaten. \n",
            "to reach the grapes, the fox had to jump high in the air. as he jumped, he opened his mouth to catch the grapes, but he missed.\n",
            "the fox tried again but missed yet again. he tried a few more times but kept failing.\n",
            "finally, the fox decided it was time to give up and go home. while he walked away, he muttered, “i’m sure the grapes were sour anyway. the end.\n",
            "Stop words removal:  ['One', 'day', ',', 'fox', 'became', 'hungry', 'went', 'search', 'food', '.', 'He', 'searched', 'high', 'low', ',', '’', 'find', 'something', 'could', 'eat', '.', 'Finally', ',', 'stomach', 'rumbled', ',', 'stumbled', 'upon', 'farmer', '’', 'wall', '.', 'At', 'top', 'wall', ',', 'saw', 'biggest', ',', 'juiciest', 'grapes', '’', 'ever', 'seen', '.', 'They', 'rich', ',', 'purple', 'color', ',', 'telling', 'fox', 'ready', 'eaten', '.', 'To', 'reach', 'grapes', ',', 'fox', 'jump', 'high', 'air', '.', 'As', 'jumped', ',', 'opened', 'mouth', 'catch', 'grapes', ',', 'missed', '.', 'The', 'fox', 'tried', 'missed', 'yet', '.', 'He', 'tried', 'times', 'kept', 'failing', '.', 'Finally', ',', 'fox', 'decided', 'time', 'give', 'go', 'home', '.', 'While', 'walked', 'away', ',', 'muttered', ',', '“', 'I', '’', 'sure', 'grapes', 'sour', 'anyway', '.', 'The', 'end', '.']\n",
            "Stemming:  ['one', 'day', ',', 'fox', 'becam', 'hungri', 'went', 'search', 'food', '.', 'he', 'search', 'high', 'low', ',', '’', 'find', 'someth', 'could', 'eat', '.', 'final', ',', 'stomach', 'rumbl', ',', 'stumbl', 'upon', 'farmer', '’', 'wall', '.', 'at', 'top', 'wall', ',', 'saw', 'biggest', ',', 'juiciest', 'grape', '’', 'ever', 'seen', '.', 'they', 'rich', ',', 'purpl', 'color', ',', 'tell', 'fox', 'readi', 'eaten', '.', 'to', 'reach', 'grape', ',', 'fox', 'jump', 'high', 'air', '.', 'as', 'jump', ',', 'open', 'mouth', 'catch', 'grape', ',', 'miss', '.', 'the', 'fox', 'tri', 'miss', 'yet', '.', 'he', 'tri', 'time', 'kept', 'fail', '.', 'final', ',', 'fox', 'decid', 'time', 'give', 'go', 'home', '.', 'while', 'walk', 'away', ',', 'mutter', ',', '“', 'i', '’', 'sure', 'grape', 'sour', 'anyway', '.', 'the', 'end', '.']\n",
            "Lemmatization:  ['One', 'day', ',', 'fox', 'became', 'hungry', 'went', 'search', 'food', '.', 'He', 'searched', 'high', 'low', ',', '’', 'find', 'something', 'could', 'eat', '.', 'Finally', ',', 'stomach', 'rumbled', ',', 'stumbled', 'upon', 'farmer', '’', 'wall', '.', 'At', 'top', 'wall', ',', 'saw', 'biggest', ',', 'juiciest', 'grape', '’', 'ever', 'seen', '.', 'They', 'rich', ',', 'purple', 'color', ',', 'telling', 'fox', 'ready', 'eaten', '.', 'To', 'reach', 'grape', ',', 'fox', 'jump', 'high', 'air', '.', 'As', 'jumped', ',', 'opened', 'mouth', 'catch', 'grape', ',', 'missed', '.', 'The', 'fox', 'tried', 'missed', 'yet', '.', 'He', 'tried', 'time', 'kept', 'failing', '.', 'Finally', ',', 'fox', 'decided', 'time', 'give', 'go', 'home', '.', 'While', 'walked', 'away', ',', 'muttered', ',', '“', 'I', '’', 'sure', 'grape', 'sour', 'anyway', '.', 'The', 'end', '.']\n",
            "Part of speech tagger:  [('One', 'CD'), ('day', 'NN'), (',', ','), ('fox', 'NN'), ('became', 'VBD'), ('hungry', 'JJ'), ('went', 'VBD'), ('search', 'JJ'), ('food', 'NN'), ('.', '.'), ('He', 'PRP'), ('searched', 'VBD'), ('high', 'RB'), ('low', 'JJ'), (',', ','), ('’', 'JJ'), ('find', 'VBP'), ('something', 'NN'), ('could', 'MD'), ('eat', 'VB'), ('.', '.'), ('Finally', 'RB'), (',', ','), ('stomach', 'NN'), ('rumbled', 'VBD'), (',', ','), ('stumbled', 'VBD'), ('upon', 'IN'), ('farmer', 'NN'), ('’', 'NNP'), ('wall', 'NN'), ('.', '.'), ('At', 'IN'), ('top', 'JJ'), ('wall', 'NN'), (',', ','), ('saw', 'VBD'), ('biggest', 'JJS'), (',', ','), ('juiciest', 'JJS'), ('grapes', 'NNS'), ('’', 'VBP'), ('ever', 'RB'), ('seen', 'VBN'), ('.', '.'), ('They', 'PRP'), ('rich', 'VBP'), (',', ','), ('purple', 'JJ'), ('color', 'NN'), (',', ','), ('telling', 'VBG'), ('fox', 'JJ'), ('ready', 'JJ'), ('eaten', 'NN'), ('.', '.'), ('To', 'TO'), ('reach', 'VB'), ('grapes', 'NNS'), (',', ','), ('fox', 'JJ'), ('jump', 'NN'), ('high', 'JJ'), ('air', 'NN'), ('.', '.'), ('As', 'IN'), ('jumped', 'NN'), (',', ','), ('opened', 'VBD'), ('mouth', 'JJ'), ('catch', 'NN'), ('grapes', 'NNS'), (',', ','), ('missed', 'VBN'), ('.', '.'), ('The', 'DT'), ('fox', 'NN'), ('tried', 'VBD'), ('missed', 'VBN'), ('yet', 'RB'), ('.', '.'), ('He', 'PRP'), ('tried', 'VBD'), ('times', 'NNS'), ('kept', 'VBD'), ('failing', 'VBG'), ('.', '.'), ('Finally', 'RB'), (',', ','), ('fox', 'NN'), ('decided', 'VBD'), ('time', 'NN'), ('give', 'VB'), ('go', 'VB'), ('home', 'NN'), ('.', '.'), ('While', 'IN'), ('walked', 'VBN'), ('away', 'RB'), (',', ','), ('muttered', 'VBD'), (',', ','), ('“', 'FW'), ('I', 'PRP'), ('’', 'VBP'), ('sure', 'JJ'), ('grapes', 'NNS'), ('sour', 'JJ'), ('anyway', 'RB'), ('.', '.'), ('The', 'DT'), ('end', 'NN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Define the corpus\n",
        "corpus = \"\"\"One day, a fox became very hungry as he went to search for some food. He searched high and low, but couldn’t find something that he could eat.\n",
        "Finally, as his stomach rumbled, he stumbled upon a farmer’s wall. At the top of the wall, he saw the biggest, juiciest grapes he’d ever seen.\n",
        "They had a rich, purple color, telling the fox they were ready to be eaten. \n",
        "To reach the grapes, the fox had to jump high in the air. As he jumped, he opened his mouth to catch the grapes, but he missed.\n",
        "The fox tried again but missed yet again. He tried a few more times but kept failing.\n",
        "Finally, the fox decided it was time to give up and go home. While he walked away, he muttered, “I’m sure the grapes were sour anyway. The end.\"\"\"\n",
        "\n",
        "# Word segmentation\n",
        "words = nltk.word_tokenize(corpus)\n",
        "print(\"Word segmentation: \", words)\n",
        "\n",
        "# Sentence segmentation\n",
        "sentences = nltk.sent_tokenize(corpus)\n",
        "print(\"Sentence segmentation: \", sentences)\n",
        "\n",
        "# Convert to lowercase\n",
        "corpus = corpus.lower()\n",
        "print(\"Lowercase: \", corpus)\n",
        "\n",
        "# Stop words removal\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "filtered_words = [word for word in words if word not in stopwords]\n",
        "print(\"Stop words removal: \", filtered_words)\n",
        "\n",
        "# Stemming\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "print(\"Stemming: \", stemmed_words)\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "print(\"Lemmatization: \", lemmatized_words)\n",
        "\n",
        "# Part of speech tagger\n",
        "tagged_words = nltk.pos_tag(filtered_words)\n",
        "print(\"Part of speech tagger: \", tagged_words)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}